---
title: "BAN 614 Winter 2023 Final Project"
output: 
  html_document:
    toc: true
    toc_float: true
---
## Brendan Flynn

## 1. Data preparation and Exploratory Data Analysis
* Follow concepts learnt in Week 2 to clean the data. If there are missing values then indicate how you
plan to work with them.
* Explore the data set and use data visualization to describe underlying trends. You can make observations on the distributions of each variable.
* Report your detailed observations of any apparent relationship between customer status and each
independent variable.
* Create any new columns if you need to at this point.
* Once you are done with the above, split the data set randomly into a training set (80%) and a test set
(20%).

```{r}
library(tidyverse)
library(ISLR)
Customer_Retention <- CustomerRetention
glimpse(Customer_Retention)
library(pROC)
```
##  Finding Missing Value Information
```{r}
# Finding the number of missing values in the data set
missing_values_info <- is.na(Customer_Retention) %>% 
  colSums()
missing_values_info
```

```{r}
# Creating a Cleaned dataset

missing_data <- Customer_Retention %>% 
  group_by(PhoneService,MultipleLines,InternetService,OnlineSecurity,OnlineBackup,DeviceProtection,TechSupport,StreamingTV,StreamingMovies) %>%  
  mutate(TotalCharges = ifelse(is.na(TotalCharges), mean(TotalCharges, na.rm = TRUE), TotalCharges))
```

```{r}
Customer_Retention_complete_data <- na.omit(missing_data)
missing_values_info <- is.na(Customer_Retention_complete_data) %>% 
  colSums()
missing_values_info

```



```{r}
# Covert Status to a factor variable
Customer_Retention_complete_data <- Customer_Retention_complete_data %>%  mutate(Status = as.factor(Status))
```


## Distribution of Variables
```{r fig.width = 7, fig.height = 35, dpi = 96}
visualize(
  CustomerRetention, 
  xvar = c(
    "Gender", "SeniorCitizen", "Partner", "Dependents", "Tenure", 
    "PhoneService", "MultipleLines", "InternetService", "OnlineSecurity", 
    "OnlineBackup", "DeviceProtection", "TechSupport", "StreamingTV", 
    "StreamingMovies", "Contract", "PaperlessBilling", "PaymentMethod", 
    "MonthlyCharges", "TotalCharges", "Status"
  ), 
  type = "dist", 
  custom = FALSE
)
```


### Distribution Observations
First, the gender histogram shows an even distribution between males and females. Next, the second histogram shows the customer base consisting of a majority of non-senior citizens. The third variable is whether customers have a partner. The histogram illustrates approximately an even distribution of customers who have a partner and customers who do not have a partner, but a slight majority of customers do not have a partner. The fourth histogram shows most customers do not have dependents. This telecommunications company is also interested in the tenure of its customers. The histogram has a slight skew to the right of the data, indicating the greatest majority of customers have only been with the company between 0 and 10 months. Next, most customers have phone service as indicated by the distribution of the phone service histogram. Among customers who have phone services, a slight majority do not have multiple lines. Customers with internet service typically have Fiber Optic over DSL. Customers with internet services, a majority of them do not have online security, online backup, device protection or tech support. Additionally, customers with internet services, an even split of customers have streaming movies and streaming TV. The contract length for customers tends to be month to month based on the histogram. Customers prefer paperless billing, and a slight majority of customers prefer to pay using an electronic check. Finally, the monthly and total charge histograms are skewed to the right and most customers in the data set are currently customers.


## Correlation Matrix


```{r}
Customer_corr_Matrix <- correlation(Customer_Retention_complete_data)
Customer_corr_Matrix
```


### Correlation Matrix Observations 
Customer Status does not have any apparent relationships with other variables. It has a very weak negative correlation with most of the variables except senior citizen, phone service, multiple lines and monthly charges. Customer status has very weak positive correlation with these variables. The variable with the strongest correlation with customer status is tenure. However, it only has -0.35 correlation with the status variable. This should not warrant any future attention.


```{r}
# Modify the contents of the 'Multiple Lines' column
Customer_Retention_complete_data <- Customer_Retention_complete_data %>% mutate(MultipleLines2 = MultipleLines)

rep_str = c("No phone service"="No")
Customer_Retention_complete_data$MultipleLines2 <- str_replace_all(Customer_Retention_complete_data$MultipleLines2,rep_str)


# Modify the contents of the 'Online Security' column
Customer_Retention_complete_data <- Customer_Retention_complete_data %>% mutate(OnlineSecurity2 = OnlineSecurity)
rep_str = c("No internet service"="No")
Customer_Retention_complete_data$OnlineSecurity2 <- str_replace_all(Customer_Retention_complete_data$OnlineSecurity2,rep_str)

# Modify the contents of the 'Online Backup' column
Customer_Retention_complete_data <- Customer_Retention_complete_data %>% mutate(OnlineBackup2 = OnlineBackup)
rep_str = c("No internet service"="No")
Customer_Retention_complete_data$OnlineBackup2 <- str_replace_all(Customer_Retention_complete_data$OnlineBackup2,rep_str)

# Modify the contents of the 'Device Protection' column
Customer_Retention_complete_data <- Customer_Retention_complete_data %>% mutate(DeviceProtection2 = DeviceProtection)
rep_str = c("No internet service"="No")
Customer_Retention_complete_data$DeviceProtection2 <- str_replace_all(Customer_Retention_complete_data$DeviceProtection2,rep_str)


# Modify the contents of the 'Tech Support' column
Customer_Retention_complete_data <- Customer_Retention_complete_data %>% mutate(TechSupport2 = TechSupport)
rep_str = c("No internet service"="No")
Customer_Retention_complete_data$TechSupport2 <- str_replace_all(Customer_Retention_complete_data$TechSupport2,rep_str)

# Modify the contents of the 'Streaming TV' column
Customer_Retention_complete_data <- Customer_Retention_complete_data %>% mutate(StreamingTV2 = StreamingTV)
rep_str = c("No internet service"="No")
Customer_Retention_complete_data$StreamingTV2 <- str_replace_all(Customer_Retention_complete_data$StreamingTV2,rep_str)

# Modify the contents of the 'Streaming Movies' column
Customer_Retention_complete_data <- Customer_Retention_complete_data %>% mutate(StreamingMovies2 = StreamingMovies)
rep_str = c("No internet service"="No")
Customer_Retention_complete_data$StreamingMovies2 <- str_replace_all(Customer_Retention_complete_data$StreamingMovies2,rep_str)

Customer_Retention_complete_data


```



```{r}
# Creating a training and test data set
set.seed(2)
train <- sample(1:5599)
customer.train <- Customer_Retention_complete_data[train,]
customer.test <- Customer_Retention_complete_data[-train,]

customer.train
```
## 2. Logistic Regression
* Use the training set to build a Logistic Regression model to predict the probability for losing a customer.
* Try different combinations of variables and arrive at the model that maximizes AUC (Area Under the
Curve) for the ROC plots.
* For the model with the highest AUC, interpret each coefficient and provide guidance to the reader on
how varying the different variables will influence customer behavior.
* Try different thresholds to identify the threshold with the highest prediction accuracy on the test set.


```{r}
# Logistic Regression model 
LogisticModel.train <- glm(Status ~ Gender + SeniorCitizen + Partner + Dependents + Tenure + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges,data = customer.train, family = binomial)
LogisticModel.train

# Create the summary of the Logistic Regression Model
summary(LogisticModel.train)
```
```{r}
# Predictions 
customer.predictions.test <- predict(LogisticModel.train,customer.test,type = "response")
head(customer.predictions.test)
Probability_Left <- customer.predictions.test/ sum(customer.predictions.test)
customer_thresholds <- data.frame(Probability_Left)
```

```{r}
roc(customer.test$Status,customer_thresholds$Probability_Left,plot=TRUE,print.auc=TRUE)
```


```{r}
# Looking for Improved Logistic Model without variables: Gender, Senior Citizen, Partner, Dependents, Phone Service, Online Security, Online Backup, Device Protection and Tech Support

# Store the Logistic Regression model in Logistic Model
LogisticModel.train <- glm(Status ~ Tenure + MultipleLines2 + InternetService + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges,data = customer.train, family = binomial)
LogisticModel.train

# Create the summary of the Logistic Regression Model
summary(LogisticModel.train)
```
```{r}
customer.predictions.test <- predict(LogisticModel.train,customer.test,type = "response")
head(customer.predictions.test)
Probability_Left <- customer.predictions.test/ sum(customer.predictions.test)
customer_thresholds <- data.frame(Probability_Left)
```

```{r}
roc(customer.test$Status,customer_thresholds$Probability_Left,plot=TRUE,print.auc=TRUE)
```


```{r}
# Looking for Improved Logistic Model without variables: Senior Citizen, Partner, Dependents, Phone Service, Multiple Lines, Online Security, Device Protection and  Online Backup

# Store the Logistic Regression model in Logistic Model
LogisticModel.train <- glm(Status ~ Gender + InternetService + Tenure + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges,data = customer.train, family = binomial)
LogisticModel.train

# Create the summary of the Logistic Regression Model
summary(LogisticModel.train)
```
```{r}
customer.predictions.test <- predict(LogisticModel.train,customer.test,type = "response")
head(customer.predictions.test)
Probability_Left <- customer.predictions.test/ sum(customer.predictions.test)
customer_thresholds <- data.frame(Probability_Left)
```

```{r}
roc(customer.test$Status,customer_thresholds$Probability_Left,plot=TRUE,print.auc=TRUE)
```


```{r}
# Model without using the variable dependents
LogisticModel.train <- glm(Status ~ Gender + SeniorCitizen + Partner + Tenure + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges,data = customer.train, family = binomial)
LogisticModel.train

# Create the summary of the Logistic Regression Model
summary(LogisticModel.train)
```
```{r}
customer.predictions.test <- predict(LogisticModel.train,customer.test,type = "response")
head(customer.predictions.test)
Probability_Left <- customer.predictions.test/ sum(customer.predictions.test)
customer_thresholds <- data.frame(Probability_Left)
```

```{r}
roc(customer.test$Status,customer_thresholds$Probability_Left,plot=TRUE,print.auc=TRUE)
```
### Model Choice
I ran three different logistical regression models with a different set of variables in each model. The 2nd model had the same AUC value as the last model but it was a simpler model, therefore, I will be using this model to make predictions.

```{r}
# Looking for Improved Logistic Model without variables: Gender, Senior Citizen, Partner, Dependents, Phone Service, Online Security, Online Backup, Device Protection and Tech Support

# Store the Logistic Regression model in Logistic Model
LogisticModel.train <- glm(Status ~ Tenure + MultipleLines2 + InternetService + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges,data = customer.train, family = binomial)
LogisticModel.train

```

## Intepretation of Coefficients


### Tenure

```{r}
odds_ratio_tenure <- exp(coef(LogisticModel.train)["Tenure"])
odds_ratio_tenure
```
The  log odds of a current customer leaving increase by .94 as the number of months as a customer increase by 1.


### Multiple Lines

```{r}
odds_ratio_MultipleLines <- exp(coef(LogisticModel.train)["MultipleLines2Yes"])
odds_ratio_MultipleLines
```
The log odds change by a factor of 1.61 when the customer status does not have multiple lines to when the customer has multiple lines.


### Internet Service

```{r}
odds_ratio_InternetService <- exp(coef(LogisticModel.train)["InternetServiceFiber optic"])
odds_ratio_InternetService
odds_ratio_InternetService2 <- exp(coef(LogisticModel.train)["InternetServiceNo"])
odds_ratio_InternetService2
```
The log odds change by a factor of 7.55 when the customer status changes from DSL internet service to Fiber Optic. Additionally, The odds change by a factor of .17 when the customer has internet service and the customer does not have internet service.


### Streaming TV

```{r}
odds_ratio_StreamingTV <- exp(coef(LogisticModel.train)["StreamingTV2Yes"])
odds_ratio_StreamingTV
```
The log odds change by a factor of 1.9 when the customer does not have streaming TV to when the customer has streaming TV.

### Streaming Movies

```{r}
odds_ratio_StreamingMovies <- exp(coef(LogisticModel.train)["StreamingMovies2Yes"])
odds_ratio_StreamingMovies
```
The log odds change by a factor of 1.9 when the customer does not have streaming TV to when the customer has streaming movies

### Contract

```{r}
odds_ratio_Contract <- exp(coef(LogisticModel.train)["ContractOne year"])
odds_ratio_Contract
odds_ratio_Contract2 <- exp(coef(LogisticModel.train)["ContractTwo year"])
odds_ratio_Contract2
```
The log odds change by a factor of .52 when the customer has a month to month contract to when the customer has a one year contract. Additionally, The log odds change by a factor of .22 when the customer has a month to month contract to when the customer has a two year contract. 

### Paperless Billing

```{r}
odds_ratio_PaperlessBilling <- exp(coef(LogisticModel.train)["PaperlessBillingYes"])
odds_ratio_PaperlessBilling
```
The log odds change by a factor of 1.48 when the customer does not have paperless billing to when the customer has Paperless Billing.

### Payment Method

```{r}
odds_ratio_PaymentMethod <- exp(coef(LogisticModel.train)["PaymentMethodCredit card (automatic)"])
odds_ratio_PaymentMethod
odds_ratio_PaymentMethod2 <- exp(coef(LogisticModel.train)["PaymentMethodElectronic check"])
odds_ratio_PaymentMethod2
odds_ratio_PaymentMethod3 <- exp(coef(LogisticModel.train)["PaymentMethodMailed check"])
odds_ratio_PaymentMethod3
```
The log odds change by a factor of .91 when the customer uses a credit card as a payment method rather than a bank transfer. The log odds change by a factor of 1.46 when the customer uses a electronic check as a payment method rather than a bank transfer.  The log odds change by a factor of .98 when the customer uses a mailed check as a payment method rather than a bank transfer.

### Total Charges

```{r}
odds_ratio_TotalCharges <- exp(coef(LogisticModel.train)["TotalCharges"])
odds_ratio_TotalCharges
```
The log odds of leaving as a customer increase by 1 as the total charge increase by 1.

### Monthly Charges

```{r}
odds_ratio_MonthlyCharges <- exp(coef(LogisticModel.train)["MonthlyCharges"])
odds_ratio_MonthlyCharges
```
The log odds of leaving as a customer increase by .96 as the monthly charge increase by 1.


### Prediction Probabilities with Selected Model

```{r}
# Prediction Probabilities
Predictions_Probabilities <- predict(LogisticModel.train,type = "response",newdata = customer.test)
Predictions_Probabilities[1:10]

```
```{r}
# Assigning Prediction Classes
Prediction_Classes <- ifelse(Predictions_Probabilities > 0.5, "Left", "Current")
Prediction_Classes[1:10]
```

```{r}
# Creating a Confusion Matrix
table(Prediction_Classes,customer.test$Status)
```
```{r}
# Prediction Accuracy of Matrix
(909+206)/(909+206+174+111)*100
```

```{r}
# Trying a different Threshold
Prediction_Classes <- ifelse(Predictions_Probabilities > 0.55, "Left", "Current")
Prediction_Classes[1:10]
```

```{r}
# Creating a Confusion Matrix
table(Prediction_Classes,customer.test$Status)
```

```{r}
# Prediction Accuracy of Matrix
(938+180)/(938+180+200+82)*100
```
```{r}
# Trying a different Threshold
Prediction_Classes <- ifelse(Predictions_Probabilities > 0.45, "Left", "Current")
Prediction_Classes[1:10]
```
```{r}
# Creating a Confusion Matrix
table(Prediction_Classes,customer.test$Status)
```

```{r}
# Prediction Accuracy of Matrix
(892+217)/(892+217+128+163)*100
```
### Overall Takeaways
I ran three different logistical regression models with a different set of variables in each model. The 2nd model was the best model. The threshold with the highest prediction accuracy that I tested was 0.55 with a prediction accuracy of 79.8


## 3. Naive Bayes
* Use the training set to build a Naive Bayes model to predict the probability for losing a customer.
* Try different combinations of variables and arrive at the model that maximizes AUC (Area Under the
Curve) for the ROC plots.
* For the model with the highest AUC, try different thresholds to identify the threshold with the highest
prediction accuracy on the test set.

```{r}
# Convert all variables to factor 
Customer_Retention_complete_data$SeniorCitizen <- as.factor(Customer_Retention_complete_data$SeniorCitizen)


```

```{r}
# Binning the Variable Tenure

Customer_Retention_complete_data <- Customer_Retention_complete_data %>%
  mutate(Tenure_binned = ifelse(Tenure < 20, "Short", ifelse(Tenure > 60, "Long", "Medium"))) %>%
  mutate(Tenure_binned = as.factor(Tenure_binned))

```


```{r}
# Binning the Variable Monthly Charges
Customer_Retention_complete_data <- Customer_Retention_complete_data %>%
  mutate(mcharges_binned = ifelse(MonthlyCharges < 50, "Small", ifelse(MonthlyCharges > 80, "Large", "Medium"))) %>%
  mutate(mcharges_binned = as.factor(mcharges_binned))
```

```{r}
# Binning the Variable Total Charges
Customer_Retention_complete_data <- Customer_Retention_complete_data %>%
  mutate(tcharges_binned = ifelse(TotalCharges < 1000, "Small", ifelse(TotalCharges > 5000, "Large", "Medium"))) %>%
  mutate(tcharges_binned = as.factor(tcharges_binned))
```


```{r}
# Create train and Test data set
set.seed(2)
train <- sample(1:5599)
customer.train <- Customer_Retention_complete_data[train,]
customer.test <- Customer_Retention_complete_data[-train,]

customer.train
```
```{r}
# Load the e1071 package to access Naive Bayes
library(e1071)
# Load the tidyverse
library(tidyverse)
library(naivebayes)
```
```{r}
# Run Naive Bayes Model with binned variables
Customer_Naive_Model <- naiveBayes(Status ~ Gender + SeniorCitizen + Partner + Dependents + Tenure_binned + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + mcharges_binned + tcharges_binned,customer.train,laplace = .01)
Customer_Naive_Model
```

```{r}
# predictions and posterior probabilities

customer.predictions <- predict(Customer_Naive_Model, newdata = customer.test)
head(customer.predictions)
```
```{r}
customer.predictions.test <- predict(Customer_Naive_Model,customer.test,type = "raw")
head(customer.predictions.test)
Probability_Left <- customer.predictions.test[,1]
customer_thresholds <- data.frame(Probability_Left)
```

```{r}
roc(customer.test$Status,customer_thresholds$Probability_Left,plot=TRUE,print.auc=TRUE)
```



```{r}
# Naive Bayes Model with binned variables and no dependents and partner
Customer_Naive_Model <- naiveBayes(Status ~ Gender + SeniorCitizen + Tenure_binned + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + mcharges_binned + tcharges_binned,customer.train,laplace = .01)
Customer_Naive_Model
```
```{r}
# predictions and posterior probabilities

customer.predictions <- predict(Customer_Naive_Model, newdata = customer.test)
head(customer.predictions)
```
```{r}
customer.predictions.test <- predict(Customer_Naive_Model,customer.test,type = "raw")
head(customer.predictions.test)
Probability_Left <- customer.predictions.test[,1]
customer_thresholds <- data.frame(Probability_Left)
```

```{r}
roc(customer.test$Status,customer_thresholds$Probability_Left,plot=TRUE,print.auc=TRUE)
```

```{r}
# Naive Bayes Model with binned variables and No Dependents, Partner,Contract and Paperless Billing
Customer_Naive_Model <- naiveBayes(Status ~ SeniorCitizen + Tenure_binned + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + PaymentMethod + mcharges_binned + tcharges_binned,customer.train,laplace = .01)
Customer_Naive_Model
```
```{r}
# predictions and posterior probabilities

customer.predictions <- predict(Customer_Naive_Model, newdata = customer.test)
head(customer.predictions)
```
```{r}
customer.predictions.test <- predict(Customer_Naive_Model,customer.test,type = "raw")
head(customer.predictions.test)
Probability_Left <- customer.predictions.test[,1]
customer_thresholds <- data.frame(Probability_Left)
```

```{r}
roc(customer.test$Status,customer_thresholds$Probability_Left,plot=TRUE,print.auc=TRUE)
```
### Chosen Model
 Out of the three different models, the best model is the second model without the variables dependents and partner. It has the same area under the curve as the first model, but it is a simpler model because it has fewer variables.


```{r}
# Naive Bayes Model with binned variables and no dependents and partner
Customer_Naive_Model <- naiveBayes(Status ~ Gender + SeniorCitizen + Tenure_binned + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + mcharges_binned + tcharges_binned,customer.train,laplace = .01)
Customer_Naive_Model
```


```{r}

customer.predictions <- predict(Customer_Naive_Model, newdata = customer.test)
head(customer.predictions)
```




```{r}
# Extract the second column of the array and store
Customer.predictions.test.yes.prob <- Customer.predictions.test.prob[,2]
# Now you can set your own cutoff and assign the class. Here I am using 0.4
Customer.predictions.test.class0.4 <- ifelse(Customer.predictions.test.yes.prob >0.4, "Yes", "No")
```

```{r}
# Extract the second column of the array and store
Customer.predictions.test.yes.prob <- Customer.predictions.test.prob[,2]
# Now you can set your own cutoff and assign the class. Here I am using 0.6
Customer.predictions.test.class0.6 <- ifelse(Customer.predictions.test.yes.prob >0.6, "Yes", "No")
```


```{r}
#### Create the confusion matrix
# First we will plot the default case, i.e, if posterior probability is more than 0.5 then homeowner else not
table(customer.predictions,customer.test$Status)
```
```{r}
# Prediction Accuracy of Matrix 
(843+255)/(843+255+177+125)*100
```

```{r}
# Here we set a more liberal threshold, i.e., 0.40
table(Customer.predictions.test.class0.4, customer.test$Status)
```
```{r}
# Prediction Accuracy of Matrix
(803+269)/(803+269+111+217)*100
```

```{r}
# Threshold of 0.60
table(Customer.predictions.test.class0.6,customer.test$Status)


```
```{r}
# Prediction Accuracy of Matrix
(861+229)/(861+229+151+159)*100
```
### Overall Takeaways

 The best model was the second model that did not include the variables dependent and partners. The best threshold was the 0.50 threshold as it had the highest prediction accuracy of 78.07.


## 4. Linear Discriminant Analysis
* Use the training set to build a model using Linear Discriminant Analysis to predict the probability
for losing a customer.
* Try different combinations of variables and arrive at the model that maximizes AUC (Area Under the
Curve) for the ROC plots.
* For the model with the highest AUC, try different thresholds to identify the threshold with the highest
prediction accuracy on the test set.


```{r}
library(MASS)
```

```{r}
#  Building LDA Model
Customer_lda <- lda(Status ~ Gender + SeniorCitizen + Partner + Dependents + Tenure + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges,data = customer.train)
Customer_lda
```
```{r}
Customer_lda_pred <-predict(Customer_lda,customer.test)
```



```{r}
# We can do it by accessing the list object *customer_lda_pred*. We first use the name *posterior* within double braces to access the matrix and then refer to the second column of the matrix using the square brackets. 

Probability_Left <- Customer_lda_pred[["posterior"]][,2]

# * We then save it as a data frame and then also add the actual customer values from the original data set.

customer_thresholds <- data.frame(Probability_Left)
customer_thresholds$Actual_Left <- customer.test$Status

roc(customer_thresholds$Actual_Left,customer_thresholds$Probability_Left,plot=TRUE,print.auc=TRUE)
```

```{r}
# LDA Model with interaction Term

Customer_lda <- lda(Status ~ Gender + Partner + SeniorCitizen + Dependents + Tenure + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges + StreamingMovies2*StreamingTV2,data = customer.train)
Customer_lda
```

```{r}
# Predictions
Customer_lda_pred <-predict(Customer_lda,customer.test)
```


```{r}
Probability_Left <- Customer_lda_pred[["posterior"]][,2]

# * We then save it as a data frame and then also add the actual customer values from the original data set.

customer_thresholds <- data.frame(Probability_Left)
customer_thresholds$Actual_Left <- customer.test$Status

# We now add another column and assign classes based on the threshold of 40%. If the posterior is > 0.4 then we assign a "Left" , else "Current".

customer_thresholds <- customer_thresholds %>% 
  mutate(Class_th_0.4 = ifelse(Probability_Left > 0.4, "Left", "Current"), Class_th_0.4 = factor(Class_th_0.4, levels=c("Left","Current")))


```


```{r}
roc(customer_thresholds$Actual_Left,customer_thresholds$Probability_Left,plot=TRUE,print.auc=TRUE)
```

```{r}
# LDA with Tenure Squared 
Customer_lda <- lda(Status ~ Gender + Partner + SeniorCitizen + Dependents + Tenure^2 + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges + StreamingMovies2*StreamingTV2,data = customer.train)
Customer_lda
```

```{r}
# Predictions
Customer_lda_pred <-predict(Customer_lda,customer.test)
```


```{r}
Probability_Left <- Customer_lda_pred[["posterior"]][,2]

# * We then save it as a data frame and then also add the actual customer values from the original data set.

customer_thresholds <- data.frame(Probability_Left)
customer_thresholds$Actual_Left <- customer.test$Status

# We now add another column and assign classes based on the threshold of 40%. If the posterior is > 0.2 then we assign a "Left" , else "Current".

customer_thresholds <- customer_thresholds %>% 
  mutate(Class_th_0.4 = ifelse(Probability_Left > 0.4, "Left", "Current"), Class_th_0.4 = factor(Class_th_0.4, levels=c("Left","Current")))

```

```{r}
roc(customer_thresholds$Actual_Left,customer_thresholds$Probability_Left,plot=TRUE,print.auc=TRUE)
```
### Chosen Model
All Three Models had the same AUC so I chose the simplest model which was the original model with all the variables.

```{r}
Customer_lda <- lda(Status ~ Gender + SeniorCitizen + Partner + Dependents + Tenure + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges,data = customer.train)
Customer_lda
```

```{r}
Customer_lda_pred <-predict(Customer_lda,customer.test)
```

```{r}
# Confusion Matrix on LDA Model
library(caret)
Customer_confusion_matrix <- confusionMatrix(Customer_lda_pred$class,customer.test$Status,positive = "Current")
Customer_confusion_matrix
```
```{r}
# We can do it by accessing the list object *customer_lda_pred*. We first use the name *posterior* within double braces to access the matrix and then refer to the second column of the matrix using the square brackets. 

Probability_Left <- Customer_lda_pred[["posterior"]][,2]

# * We then save it as a data frame and then also add the actual customer values from the original data set.

customer_thresholds <- data.frame(Probability_Left)
customer_thresholds$Actual_Left <- customer.test$Status

# We now add another column and assign classes based on the threshold of 40%. If the posterior is > 0.4 then we assign a "left" , else "current".

customer_thresholds <- customer_thresholds %>% 
  mutate(Class_th_0.4 = ifelse(Probability_Left > 0.4, "Left", "Current"), Class_th_0.4 = factor(Class_th_0.4, levels=c("Left","Current")))

```

```{r}
# Different Sensitivity Confusion Matrix
Confusion_Matrix <- confusionMatrix(customer_thresholds$Class_th_0.4,customer_thresholds$Actual_Left)
Confusion_Matrix
```
```{r}
# Different Threshold
customer_thresholds <- customer_thresholds %>% 
  mutate(Class_th_0.6 = ifelse(Probability_Left > 0.6, "Left", "Current"), Class_th_0.6 = factor(Class_th_0.6, levels=c("Left","Current")))

Confusion_Matrix <- confusionMatrix(customer_thresholds$Class_th_0.6,customer_thresholds$Actual_Left)
Confusion_Matrix
```






### Overall Takeaways
All Three Models had the same AUC so I chose the simplest model which was the original model with all the variables. The ideal threshold is a 60% threshold for the probability of a customer leaving as this has the highest prediction accuracy of .7971. 

## 5. Quadratic Discriminant Analysis
* Use the training set to build a model using Quadratic Discriminant Analysis to predict the probability
for losing a customer.
* Try different combinations of variables and arrive at the model that maximizes AUC (Area Under the
Curve) for the ROC plots.
* For the model with the highest AUC, try different thresholds to identify the threshold with the highest
prediction accuracy on the test set.


```{r}
# Building an QDA Model
Customer_qda <- qda(Status ~ Gender + Partner+ SeniorCitizen + Dependents + Tenure + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges,data = customer.train)
Customer_qda
```
```{r}
# Making Predictions with QDA model
Customer_qda_pred <-predict(Customer_qda,customer.test)
```

```{r}
Probability_Left <- Customer_qda_pred[["posterior"]][,2]

# * We then save it as a data frame and then also add the actual customer values from the original data set.

customer_thresholds <- data.frame(Probability_Left)
customer_thresholds$Actual_Left <- customer.test$Status

# We now add another column and assign classes based on the threshold of 40%. If the posterior is > 0.40 then we assign a "Left" , else "Current".

customer_thresholds <- customer_thresholds %>% 
  mutate(Class_th_0.4 = ifelse(Probability_Left > 0.4, "Left", "Current"), Class_th_0.4 = factor(Class_th_0.4, levels=c("Left","Current")))

```

```{r}
roc(customer_thresholds$Actual_Left,customer_thresholds$Probability_Left,plot=TRUE,print.auc=TRUE)
```
```{r}
# QDA Model with log(Monthly Charges)
Customer_qda <- qda(Status ~ Gender + Partner + SeniorCitizen + Dependents + Tenure + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + log(MonthlyCharges) + TotalCharges,data = customer.train)
Customer_qda
```
```{r}
# Making Predictions with QDA model
Customer_qda_pred <-predict(Customer_qda,customer.test)
```

```{r}
Probability_Left <- Customer_qda_pred[["posterior"]][,2]

# * We then save it as a data frame and then also add the actual customer values from the original data set.

customer_thresholds <- data.frame(Probability_Left)
customer_thresholds$Actual_Left <- customer.test$Status

# We now add another column and assign classes based on the threshold of 40%. If the posterior is > 0.40 then we assign a "Left" , else "Current".

customer_thresholds <- customer_thresholds %>% 
  mutate(Class_th_0.4 = ifelse(Probability_Left > 0.4, "Left", "Current"), Class_th_0.4 = factor(Class_th_0.4, levels=c("Left","Current")))

```

```{r}
roc(customer_thresholds$Actual_Left,customer_thresholds$Probability_Left,plot=TRUE,print.auc=TRUE)
```
```{r}
# QDA Model with sqrt(Total Charges)
Customer_qda <- qda(Status ~ Gender + Partner + SeniorCitizen + Dependents + Tenure + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + sqrt(TotalCharges),data = customer.train)
Customer_qda
```

```{r}
# Making Predictions with QDA model
Customer_qda_pred <-predict(Customer_qda,customer.test)
```

```{r}
Probability_Left <- Customer_qda_pred[["posterior"]][,2]

# * We then save it as a data frame and then also add the actual customer values from the original data set.

customer_thresholds <- data.frame(Probability_Left)
customer_thresholds$Actual_Left <- customer.test$Status

# We now add another column and assign classes based on the threshold of 40%. If the posterior is > 0.40 then we assign a "Left" , else "Current".

customer_thresholds <- customer_thresholds %>% 
  mutate(Class_th_0.4 = ifelse(Probability_Left > 0.4, "Left", "Current"), Class_th_0.4 = factor(Class_th_0.4, levels=c("Left","Current")))

```

```{r}
roc(customer_thresholds$Actual_Left,customer_thresholds$Probability_Left,plot=TRUE,print.auc=TRUE)
```
### Model Choice
* The Last Model using the Square root of the total Charges has the highest area under the curve, therefore I will be using it for analysis. 

```{r}
# Confusion Matrix on QDA Model
library(caret)
Customer_confusion_matrix <- confusionMatrix(Customer_qda_pred$class,customer.test$Status,positive = "Current")
Customer_confusion_matrix
```

```{r}
# Different Threshold
customer_thresholds <- customer_thresholds %>% 
  mutate(Class_th_0.4 = ifelse(Probability_Left > 0.4, "Left", "Current"), Class_th_0.4 = factor(Class_th_0.4, levels=c("Left","Current")))

Confusion_Matrix <- confusionMatrix(customer_thresholds$Class_th_0.4,customer_thresholds$Actual_Left)
Confusion_Matrix

```
```{r}
# Different Threshold
customer_thresholds <- customer_thresholds %>% 
  mutate(Class_th_0.6 = ifelse(Probability_Left > 0.6, "Left", "Current"), Class_th_0.6 = factor(Class_th_0.6, levels=c("Left","Current")))

Confusion_Matrix <- confusionMatrix(customer_thresholds$Class_th_0.6,customer_thresholds$Actual_Left)
Confusion_Matrix

```

### Overall Takeways
The best model is the squared root of total charges. The ideal threshold is a 60% threshold for the probability of a customer leaving as this has the highest prediction accuracy of .7743

## 6. Decision Trees
* Use the training set to build a Decision Tree model to predict the probability for losing a customer.
* Try different combinations of variables and identify the model with the largest prediction accuracy.

```{r}
library(tree)
```


```{r}
# Building the Decision Tree Model
tree.Customer.train <- tree(Status ~ Gender + SeniorCitizen + Partner + Dependents + Tenure + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges, customer.train)
```

```{r}
summary(tree.Customer.train)
```
```{r echo = TRUE, fig.width=15, fig.height=6}
plot(tree.Customer.train)
# The argument *pretty = 0* instructs R to include the category names for any qualitative predictors, rather than simply displaying a letter for each category
text(tree.Customer.train, pretty = 0)
```
```{r}
tree.Customer.train
```
### Pruning the Tree
```{r echo = TRUE}
# set seed for reproducibility of analysis
set.seed(3)

# Use cross validation to determine the optimal level of tree complexity. Cost complexity pruning is used. Use *FUN = prune.misclass* in order to indicate that we want the classification error rate to guide the cross-validation and pruning process. Else the default measure is deviance.
cv.Customer <- cv.tree(tree.Customer.train, FUN = prune.misclass)

# The output from above code is a list object. It reports the number of terminal nodes of each tree considered (size), the corresponding error rate (dev), the value of the cost-complexity parameter used (k) and the method used (misclass)
str(cv.Customer)
```

Looking at the *dev* and *size* data above it looks like the tree with 6 terminal nodes results in the lowest error rate. We can plot the error rate as a function of both *size* and *k*

```{r echo = TRUE}
# This commands helps in creating space to fit multiple plots. *mfrow = c(1,2)* will take a row and split it into two columns. Once you define this space then every plot that create later will be filled into these spaces. 
par(mfrow = c(1,2))

# We created space for two plots. Here is the first plot. This will show up on the left hand side. The "type = b" plots both points and lines connecting the points. First argument in the plot function is the X axis data and the second argument is the Y-axis data
plot(cv.Customer$size, cv.Customer$dev, type = "b")

# This second plot will show up on the right hand side
plot(cv.Customer$k, cv.Customer$dev, type = "b")
```

We now apply the *prune.misclass()* function in order to prune the tree to obtain the number of terminal nodes we want.

```{r echo = TRUE}
# Prune the tree to the required number of terminal nodes
prune.customer <- prune.misclass(tree.Customer.train, best = 4)

# Plot the pruned tree. Note that this will create a tree without any labels.
plot(prune.customer)

# Need the command below to add labels to the pruned tree as text along with *pretty = 0*
text(prune.customer, pretty = 0)
```

```{r}
Status.test <- customer.test$Status
tree.pred.test <- predict(tree.Customer.train, customer.test, type = "class")

# The output from the above code will be a vector of predictions
str(tree.pred.test)

# Create the confusion matrix using the predictions vector along with the actual classification present in the test data
table(tree.pred.test,Status.test)
```

```{r}
# Prediction Accuracy of Matrix
(960+150)/(960+150+230+60)*100
```

```{r}
# Building the Decision Tree Model without variable contract
tree.Customer.train <- tree(Status ~ Gender + SeniorCitizen + Partner + Dependents + Tenure + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + DeviceProtection2 + TechSupport2 + StreamingTV2 + StreamingMovies2 + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges, customer.train)
```

```{r}
summary(tree.Customer.train)
```
```{r echo = TRUE, fig.width=15, fig.height=6}
plot(tree.Customer.train)
# The argument *pretty = 0* instructs R to include the category names for any qualitative predictors, rather than simply displaying a letter for each category
text(tree.Customer.train, pretty = 0)
```
```{r}
tree.Customer.train
```

```{r}
### Pruning the Tree
# set seed for reproducibility of analysis
set.seed(3)

# Use cross validation to determine the optimal level of tree complexity. Cost complexity pruning is used. Use *FUN = prune.misclass* in order to indicate that we want the classification error rate to guide the cross-validation and pruning process. Else the default measure is deviance.
cv.Customer <- cv.tree(tree.Customer.train, FUN = prune.misclass)

# The output from above code is a list object. It reports the number of terminal nodes of each tree considered (size), the corresponding error rate (dev), the value of the cost-complexity parameter used (k) and the method used (misclass)
str(cv.Customer)
```

```{r}
#Looking at the *dev* and *size* data above it looks like the tree with 12 terminal nodes results in the lowest error rate. We can plot the error rate as a function of both *size* and *k*

# This commands helps in creating space to fit multiple plots. *mfrow = c(1,2)* will take a row and split it into two columns. Once you define this space then every plot that create later will be filled into these spaces. 
par(mfrow = c(1,2))

# We created space for two plots. Here is the first plot. This will show up on the left hand side. The "type = b" plots both points and lines connecting the points. First argument in the plot function is the X axis data and the second argument is the Y-axis data
plot(cv.Customer$size, cv.Customer$dev, type = "b")

# This second plot will show up on the right hand side
plot(cv.Customer$k, cv.Customer$dev, type = "b")
```

```{r}
# Prune the tree to the required number of terminal nodes
prune.customer <- prune.misclass(tree.Customer.train, best = 3)

# Plot the pruned tree. Note that this will create a tree without any labels.
plot(prune.customer)

# Need the command below to add labels to the pruned tree as text along with *pretty = 0*
text(prune.customer, pretty = 0)
```

```{r}
Status.test <- customer.test$Status
tree.pred.test <- predict(tree.Customer.train, customer.test, type = "class")

# The output from the above code will be a vector of predictions
str(tree.pred.test)

# Create the confusion matrix using the predictions vector along with the actual classification present in the test data
table(tree.pred.test,Status.test)
```

```{r}
# Prediction Accuracy of Matrix
(932+169)/(932+169+211+88)*100
```

```{r}
# Building the Decision Tree Model without variables Tech Support, Streaming TV, Steaming Movies and device protection
tree.Customer.train <- tree(Status ~ Gender + SeniorCitizen + Partner + Dependents + Contract + Tenure + PhoneService + MultipleLines2 + InternetService + OnlineSecurity2 + OnlineBackup2 + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges, customer.train)
```

```{r}
summary(tree.Customer.train)
```
```{r echo = TRUE, fig.width=15, fig.height=6}
plot(tree.Customer.train)
# The argument *pretty = 0* instructs R to include the category names for any qualitative predictors, rather than simply displaying a letter for each category
text(tree.Customer.train, pretty = 0)
```

```{r}
tree.Customer.train
```
```{r}
### Pruning the Tree
# set seed for reproducibility of analysis
set.seed(3)

# Use cross validation to determine the optimal level of tree complexity. Cost complexity pruning is used. Use *FUN = prune.misclass* in order to indicate that we want the classification error rate to guide the cross-validation and pruning process. Else the default measure is deviance.
cv.Customer <- cv.tree(tree.Customer.train, FUN = prune.misclass)

# The output from above code is a list object. It reports the number of terminal nodes of each tree considered (size), the corresponding error rate (dev), the value of the cost-complexity parameter used (k) and the method used (misclass)
str(cv.Customer)
```

```{r}
#Looking at the *dev* and *size* data above it looks like the tree with 12 terminal nodes results in the lowest error rate. We can plot the error rate as a function of both *size* and *k*

# This commands helps in creating space to fit multiple plots. *mfrow = c(1,2)* will take a row and split it into two columns. Once you define this space then every plot that create later will be filled into these spaces. 
par(mfrow = c(1,2))

# We created space for two plots. Here is the first plot. This will show up on the left hand side. The "type = b" plots both points and lines connecting the points. First argument in the plot function is the X axis data and the second argument is the Y-axis data
plot(cv.Customer$size, cv.Customer$dev, type = "b")

# This second plot will show up on the right hand side
plot(cv.Customer$k, cv.Customer$dev, type = "b")
```

```{r}
# Prune the tree to the required number of terminal nodes
prune.customer <- prune.misclass(tree.Customer.train, best = 4)

# Plot the pruned tree. Note that this will create a tree without any labels.
plot(prune.customer)

# Need the command below to add labels to the pruned tree as text along with *pretty = 0*
text(prune.customer, pretty = 0)
```

```{r}
Status.test <- customer.test$Status
tree.pred.test <- predict(tree.Customer.train, customer.test, type = "class")

# The output from the above code will be a vector of predictions
str(tree.pred.test)

# Create the confusion matrix using the predictions vector along with the actual classification present in the test data
table(tree.pred.test,Status.test)
```

```{r}
# Prediction Accuracy of Matrix
(960+150)/(960+150+230+60)*100
```
### Overall Takeaways
The original model and the last model without the variables Tech Support, Streaming TV, Steaming Movies and device protection had the same prediction accuracy of 79.28. The last model is a simpler model, with fewer variables, so this is the best model. 


## 7. Comparison across Methods
* Compare across methods (skip the model built with decision trees) used above and report your best
method based on ROC plots.
* Which model does the best in terms of the prediction accuracy on the test set? Include the decision
tree model here.
* As a person in charge of making business decisions, what else are you learning from the results you are
seeing from all these methods?


### Best Method based on ROC plot
The best model based on the maximum AUC value of .841. It was a logistic model without the variables Gender, Senior Citizen, Partner, Dependents, Phone Service, Online Security, Online Backup, Device Protection and Tech Support.

### Best Model based on Prediction Accuracy
 The best model based on prediction accuracy had an a prediction accuracy value of 79.8% and a threshold of 0.55. It was also the logistic model without the variables Gender, Senior Citizen, Partner, Dependents, Phone Service, Online Security, Online Backup, Device Protection and Tech Support.

### General Takeaways 
Based on running different models I found variables that are more and less effective in determining whether the status of the customer. Variables such as gender, dependent and partner are among the least effective variables. While running different models, I found dropping these variables in models had no effect on the maximum AUC values or the model improved without these variables. On the contrary, variables such as tenure, contract, internet service and total charges are among the most effective variables in determining the status of the customer. Including these variables in models produced high AUC values. The variables tenure,contract and internet services were the most significant variables in the decision tree.

## 8. Business Analysis and Recommendations
Pretend that the training dataset reflects the past and that the test data set captures the customers we are
concerned about currently. Use your logistic regression model with your best threshold (identified in part 2)
to answer the following questions:
* In terms of relative importance how would you rate the predictors in your model. As a business
manager, which factors would you focus on (for example you could invest in offering some incentives
or promotions) to decrease the chances of customers leaving?

* Collect all the customers from the test dataset that your model says are going to leave. What is the
predicted loss in revenue per month if all these customers leave? This reflects the loss if no action is
taken
* Propose an incentive scheme to your manager that can help reduce the loss in revenue by retaining
some (or all) customers. Provide justification by evaluating costs and benefits of your incentive scheme.
Costs will be the dollar amount in incentives given (for example). Benefits will be the revenues from
these customers if they stay with your company. Compute the net benefits from your incentive scheme.
Make a case in your report to your upper management for implementing your scheme.

### Logistic Model with Best Threshold
```{r}
# Looking for Improved Logistic Model without variables: Gender, Senior Citizen, Partner, Dependents, Phone Service, Online Security, Online Backup, Device Protection and Tech Support

# Store the Logistic Regression model in Logistic Model
LogisticModel.train <- glm(Status ~ Tenure + MultipleLines2 + InternetService + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges,data = customer.train, family = binomial)
LogisticModel.train

```

```{r}
# Prediction Probabilities
Predictions_Probabilities <- predict(LogisticModel.train,type = "response",newdata = customer.test)
Predictions_Probabilities[1:10]
```

```{r}
# Trying a different Threshold
Prediction_Classes <- ifelse(Predictions_Probabilities > 0.55, "Left", "Current")
Prediction_Classes[1:10]
```

```{r}
# Creating a Confusion Matrix
table(Prediction_Classes,customer.test$Status)
```
```{r}
# Prediction Accuracy of Matrix
(938+180)/(938+200+82+180)*100
```
### Variables to focus on 
I think the top variables to focus on are tenure and contract. The goal of a company is to always grow and gain customers,but also keep their existing customers. I have explained below a proposed incentive to increase the customer tenure. Additionally, an incentive should also be implemented for contracts to keep customers at the company.       

### Loss of Revenue if Customers Leave

```{r}
customer.test_rev <- customer.test %>% 
                     filter(Status == "Left") %>% group_by(Status) %>%
                     summarize(total_monthly_charges = sum(MonthlyCharges))
customer.test_rev

```

### Sample Model with Incentive 
```{r}
Customer_Retention_complete_data <- Customer_Retention_complete_data %>% mutate(red_monthlycharges = ifelse(Tenure >= 10,1,0))
discount <- Customer_Retention_complete_data$MonthlyCharges - 5
weights <- ifelse(Customer_Retention_complete_data$red_monthlycharges == 1,discount,Customer_Retention_complete_data$MonthlyCharges)
```

```{r}
# Creating a training and test dataset
set.seed(2)
train <- sample(1:5599)
customer.train <- Customer_Retention_complete_data[train,]
customer.test <- Customer_Retention_complete_data[-train,]

customer.train
```



```{r}
LogisticModel.train <- glm(Status ~ Tenure + MultipleLines2 + InternetService + StreamingTV2 + StreamingMovies2 + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges,data = customer.train, family = binomial,weights = red_monthlycharges)
```


```{r}
# Prediction Probabilities
Predictions_Probabilities <- predict(LogisticModel.train,type = "response",newdata = customer.test)
Predictions_Probabilities[1:10]
```



```{r}
# Trying a different Threshold
Prediction_Classes <- ifelse(Predictions_Probabilities > 0.55, "Left", "Current")
Prediction_Classes[1:10]
```


```{r}
# Creating a Confusion Matrix
table(Prediction_Classes,customer.test$Status)
```
```{r}
# Prediction Accuracy of Matrix
(976+130)/(976+130+250+44)*100
```
### Incentive Model
My idea for an incentive model is to give discounts for customers based on the tenure as a customer. I noticed while looking at the initial distribution after 10 months a significant drop off in customers. Furthermore, my idea is to give $5 off monthly charges for customers who have been with the company for 10 months and longer. I created a sample model with the incentive implemented in the model. The prediction accuracy is on par with the best model. The costs of this change will be the loss in awarding the discounts to customers who have been with the customer for 10 months and longer. The benefits will be keeping existing customers for a longer period of time. In the future, a cost benefit analysis should be performed to analyze the logistics of this idea.

